{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Th·ª±c hi·ªán l∆∞u t·ª´ng d√≤ng trong c·ªôt \"ƒê√°p √°n\" th√†nh 1 chunk trong Qdrant m√† kh√¥ng c·∫ßn chia nh·ªè n·ªØa,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30364,
     "status": "ok",
     "timestamp": 1701544569753,
     "user": {
      "displayName": "phatjk",
      "userId": "06940104252696149723"
     },
     "user_tz": -420
    },
    "id": "bQ4HnUjc5WwI",
    "outputId": "422bb50e-05ad-4e47-819a-f71fae5e92c8"
   },
   "outputs": [],
   "source": [
    "### Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "!pip install langchain qdrant-client -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants for Qdrant and Hugging Face API keys\n",
    "# QDRANT_API_KEY = \"WbQ_\"\n",
    "# QDRANT_URL = \"\"\n",
    "# EMBEDDINGS_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "# HUGGINGFACE_API_KEY = \"hf_\" # Your Hugging Face API key\n",
    "# COLLECTION_NAME = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Excel data\n",
    "DATA = 'LegalRAG.xlsx'\n",
    "data = pd.read_excel(DATA)\n",
    "\n",
    "# Extract and preprocess the \"ƒê√°p √°n\" column\n",
    "answers = data[\"ƒê√°p √°n\"].dropna().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate embeddings using HuggingFaceInferenceAPIEmbeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL_NAME,\n",
    "    api_key=HUGGINGFACE_API_KEY  # Correctly setting API key\n",
    ")\n",
    "\n",
    "# Create a vector database in Qdrant\n",
    "qdrant = Qdrant.from_texts(\n",
    "    texts=answers,  # Directly use each row as a chunk\n",
    "    embedding=embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    ")\n",
    "\n",
    "# Verify if the data is added successfully\n",
    "print(f\"Number of chunks added: {len(answers)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add th√™m sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ƒê·ªÉ th√™m th√¥ng tin metadata nh∆∞ `\"source\"` v√†o m·ªói chunk v√† ƒë·ªãnh d·∫°ng nh∆∞ b·∫°n y√™u c·∫ßu, ch√∫ng ta s·∫Ω l√†m nh∆∞ sau:\n",
    "\n",
    "1. **Th√™m metadata:** G·∫Øn th√™m tr∆∞·ªùng `source` ch·ª©a ƒë∆∞·ªùng d·∫´n ƒë·∫øn t·ªáp d·ªØ li·ªáu g·ªëc.\n",
    "2. **S·ª≠ d·ª•ng v√≤ng l·∫∑p:** L·∫∑p qua c√°c chunk v√† in ra n·ªôi dung c√πng metadata nh∆∞ b·∫°n y√™u c·∫ßu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "# from langchain.vectorstores import Qdrant\n",
    "# from langchain.schema import Document  # Import Document class\n",
    "# import pandas as pd\n",
    "\n",
    "# # # Define constants for Qdrant and Hugging Face API keys\n",
    "# QDRANT_API_KEY = \"WbQ_\"\n",
    "# QDRANT_URL = \"\"\n",
    "# EMBEDDINGS_MODEL_NAME = \"\"\n",
    "# HUGGINGFACE_API_KEY = \"hf_\" # Your Hugging Face API key\n",
    "# COLLECTION_NAME = \"\"\n",
    "\n",
    "# # File source for metadata\n",
    "# SOURCE_FILE = \"LegalRAG.xlsx\"\n",
    "\n",
    "# # Load Excel data\n",
    "# data = pd.read_excel(SOURCE_FILE)\n",
    "\n",
    "# # Extract and preprocess the \"ƒê√°p √°n\" column\n",
    "# answers = data[\"ƒê√°p √°n\"].dropna().tolist()\n",
    "\n",
    "# # Add metadata to each chunk and create Document objects\n",
    "# documents = [Document(page_content=answer, metadata={\"source\": SOURCE_FILE}) for answer in answers]\n",
    "\n",
    "# # Generate embeddings using HuggingFaceInferenceAPIEmbeddings\n",
    "# embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "#     model_name=EMBEDDINGS_MODEL_NAME,\n",
    "#     api_key=HUGGINGFACE_API_KEY\n",
    "# )\n",
    "\n",
    "# # Create a vector database in Qdrant\n",
    "# qdrant = Qdrant.from_documents(\n",
    "#     documents=documents,\n",
    "#     embedding=embeddings,\n",
    "#     url=QDRANT_URL,\n",
    "#     collection_name=COLLECTION_NAME,\n",
    "#     api_key=QDRANT_API_KEY,\n",
    "#     prefer_grpc=False,\n",
    "# )\n",
    "\n",
    "# # Verify if the data is added successfully and print chunks\n",
    "# for i, doc in enumerate(documents):\n",
    "#     print(f\"Document {i + 1} content: {doc.page_content[:100]}\")  # In 100 k√Ω t·ª± ƒë·∫ßu ti√™n\n",
    "#     print(f\"Document {i + 1} metadata: {doc.metadata}\")\n",
    "#     if not doc.page_content.strip():\n",
    "#         print(f\"Document {i + 1} is empty!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "M·ªói chunk s·∫Ω c√≥ th√¥ng tin sau:\n",
    "- **`content`**: N·ªôi dung c·ªßa chunk (c√°c d√≤ng t·ª´ c·ªôt \"ƒê√°p √°n\").\n",
    "- **`metadata`**: Metadata bao g·ªìm th√¥ng tin v·ªÅ ngu·ªìn d·ªØ li·ªáu (`source`).\n",
    "\n",
    "V√≠ d·ª•:\n",
    "```plaintext\n",
    "Document 1 content: Lu·∫≠t n√†y quy ƒë·ªãnh v·ªÅ quy t·∫Øc giao th√¥ng ƒë∆∞·ªùng b·ªô; k·∫øt c·∫•u h·∫° t·∫ßng giao th√¥ng ƒë∆∞·ªùng b·ªô; ph∆∞∆°ng ti·ªán...\n",
    "Document 1 metadata: {'source': 'LegalRAG.xlsx'}\n",
    "```\n",
    "\n",
    "### Gi·∫£i th√≠ch\n",
    "1. **`documents` array**: Ch·ª©a danh s√°ch c√°c ƒëo·∫°n vƒÉn b·∫£n v·ªõi `page_content` v√† `metadata`.\n",
    "2. **Th√™m metadata `source`**: G·∫Øn th√¥ng tin ngu·ªìn t·ªáp v√†o metadata c·ªßa m·ªói chunk.\n",
    "3. **In n·ªôi dung v√† metadata**: Ki·ªÉm tra t·ª´ng chunk ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ƒë√∫ng c√°ch.\n",
    "\n",
    "H√£y th·ª≠ ch·∫°y v√† ki·ªÉm tra k·∫øt qu·∫£!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add th√™m Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra h√†ng c√≥ \"C√¢u h·ªèi\" nh∆∞ng kh√¥ng c√≥ \"ƒê√°p √°n\"\n",
    "questions_without_answers = data[data[\"C√¢u h·ªèi\"].notna() & data[\"ƒê√°p √°n\"].isna()]\n",
    "\n",
    "# Ki·ªÉm tra h√†ng c√≥ \"ƒê√°p √°n\" nh∆∞ng kh√¥ng c√≥ \"C√¢u h·ªèi\"\n",
    "answers_without_questions = data[data[\"ƒê√°p √°n\"].notna() & data[\"C√¢u h·ªèi\"].isna()]\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "print(\"Rows with questions but no answers:\")\n",
    "print(questions_without_answers)\n",
    "\n",
    "print(\"\\nRows with answers but no questions:\")\n",
    "print(answers_without_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.schema import Document  # Import Document class\n",
    "import pandas as pd\n",
    "\n",
    "QDRANT_API_KEY = \"WbQ_\"\n",
    "QDRANT_URL = \"\"\n",
    "EMBEDDINGS_MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "HUGGINGFACE_API_KEY = \"hf_\" # Your Hugging Face API key\n",
    "COLLECTION_NAME = \"\"\n",
    "\n",
    "# File source for metadata\n",
    "SOURCE_FILE = \"LegalRAG.xlsx\"\n",
    "\n",
    "# Load Excel data\n",
    "data = pd.read_excel(SOURCE_FILE)\n",
    "\n",
    "# Extract and preprocess the \"C√¢u h·ªèi\" and \"ƒê√°p √°n\" columns\n",
    "questions = data[\"C√¢u h·ªèi\"].dropna().tolist()\n",
    "answers = data[\"ƒê√°p √°n\"].dropna().tolist()\n",
    "\n",
    "# Ensure questions and answers have the same length\n",
    "assert len(questions) == len(answers), \"Mismatch between number of questions and answers!\"\n",
    "\n",
    "# Add metadata to each chunk and create Document objects\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=answer,\n",
    "        metadata={\"source\": SOURCE_FILE, \"question\": question}\n",
    "    )\n",
    "    for question, answer in zip(questions, answers)\n",
    "]\n",
    "\n",
    "# Generate embeddings using HuggingFaceInferenceAPIEmbeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL_NAME,\n",
    "    api_key=HUGGINGFACE_API_KEY\n",
    ")\n",
    "\n",
    "# Create a vector database in Qdrant\n",
    "qdrant = Qdrant.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,\n",
    ")\n",
    "\n",
    "# Verify if the data is added successfully and print chunks\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Document {i + 1} content: {doc.page_content[:100]}\")  # In 100 k√Ω t·ª± ƒë·∫ßu ti√™n\n",
    "    print(f\"Document {i + 1} metadata: {doc.metadata}\")\n",
    "    if not doc.page_content.strip():\n",
    "        print(f\"Document {i + 1} is empty!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Thay ƒë·ªïi ch√≠nh\n",
    "1. **Th√™m metadata `question`:** Th√™m tr∆∞·ªùng `question` v√†o metadata cho m·ªói chunk.\n",
    "2. **Ki·ªÉm tra ƒë·ªô d√†i danh s√°ch:** ƒê·∫£m b·∫£o r·∫±ng s·ªë l∆∞·ª£ng c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi kh·ªõp nhau ƒë·ªÉ tr√°nh l·ªói khi t·∫°o `Document`.\n",
    "3. **Metadata ƒë·∫ßy ƒë·ªß:** M·ªói `Document` gi·ªù s·∫Ω c√≥ c·∫£ tr∆∞·ªùng `source` v√† `question`.\n",
    "\n",
    "### Output\n",
    "M·ªói t√†i li·ªáu s·∫Ω c√≥ metadata nh∆∞:\n",
    "```plaintext\n",
    "Document 1 content: Lu·∫≠t n√†y quy ƒë·ªãnh v·ªÅ quy t·∫Øc giao th√¥ng ƒë∆∞·ªùng b·ªô...\n",
    "Document 1 metadata: {'source': 'LegalRAG.xlsx', 'question': 'Tr√¨nh b√†y kh√°i ni·ªám, ch·∫ø ƒë·ªô ph√°p l√Ω v√πng n·ªôi th·ªßy...'}\n",
    "``` \n",
    "\n",
    "H√£y th·ª≠ v√† ki·ªÉm tra k·∫øt qu·∫£! üòä"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMo/4/eme+yWt+NjHLhRca0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
